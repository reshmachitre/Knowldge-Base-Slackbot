Task Indexing Failure Primary Runbook (Org Sync)OverviewWe are supposed to sync all task updates to Kafka, so the indexing service can process them. We use the indexing service to display our tasks, most importantly filtered by status.SymptomsIf there is a gap in task syncing, we get reports of customers seeing completed tasks on their active tasks filter. This happens because the indexing service sees them as active, but the actual records on our end are completed.ImplicationsWhen tasks are out of sync, customers may have a hard time finding the tasks they need, because their active tasks views are clogged with completed tasks. It may also affect some triggers.Mitigations / ResolutionsThere are two approaches to fixing this issue: Check whole accounts for out of sync tasks, or sync all tasks that were updated within a window. The first option is preferable, but may run into OOM issues, leaving some accounts in a failure loop.Identifying tasks and organizations that may be affectedWhen working with UUIDs, Redash will not want the values prepended with Ôs-Õ but rake tasks will. To get the prepended values out of Redash, just add concat('s-', field_name) in the select clause of your query. This ruby script helps with transmuting ids back and forth when you have a csv file with headers: 1. Identify the time window for which the tasks are out of sync.1. ensure this is in UTC timezone2. time format is: yyyy-mm-dd hh:mm:ss2. Execute the Task Sync - Organizations with updated tasks in timeframe query in Redash1. There is a commented out where clause on ~ L:33 where you can add any organizations you may have already processed, to keep them out of the list3. Extract the organization_ids as a comma-separated list1. use prepend_noquote mode in the id_preparer script.2. you will use this list next for queueing up the rake tasksQueue up and process organizationsSync a Small Number of Tasks via Console1. Set organization context: Org.parse('MAGIC_LINK_URL')2. Gather the IDs of tasks to be resynchronized1. You can fetch them from their URLs, or2. You can query for them programmaticallytask_ids = Search::IndexingService::TaskIndexQuery.new(status: 'waiting', limit: 100).map { |e| e.id }3. Enqueue them for resynchronizationContentFlow::TaskIndexer.bulk_update(task_ids)Sync a Small Number of Organizations via Rake1. Elevate your production privileges in production2. Execute the indexing:check_task_synchronization job:1. eg: kubectl run-cmd -n content-flow-service --context production -s 2xlarge rake indexing:check_task_synchronization organization_id=s-18d2eefd-b613-47da-b4f5-a5460d10f14d sync_tasks=true2. passing sync_tasks=true will cause it to actually do the synchonization, rather than just reporting what it would do.3. Monitor the task in NewRelic1. you can add the job_id from the rake task to focus on your specific job.2. This will either complete or fail. Sometimes failure gets logged, but sometimes it goes out of memory, in which the instance will get killed.1. #content-flow-alerts will show a message like:2. If you see this repeatedly, and multiple messages like this in New Relic (with your job_id)your job likely is not going to be successful. You will have to destroy the job in rails console to make it stop looping 1. Open a write mode production Rails console (-w on the end instead of -r)2. Delayed::Job.find(123356).destroy (be super careful you have the right id!)3. If your job has failed, and you ended up destroying it, you will have to move on to Manually Syncing Tasks in a Timeframe.1. Make sure you keep a list of the organization_ids you have skipped.2. putting them in a CSV file, one per row will help you manipulate them later!Sync Many Organizations via RakeIf you need to run a bunch of organizations, it may be preferable to use these two rake tasks to queue up the work. It uses the same underlying code as indexing:check_task_synchronizationIndexing:batch_add_organizations_for_check_task_synchronizationThis job takes a list of organization_ids prepended with s-, unquoted, and comma separated. Use mode prepend_noquote in to get this format.Example:kubectl run-cmd -n content-flow-service --context production -s 2xlarge rake indexing:batch_add_organizations_for_check_task_synchronization organization_ids=s-16ce41ec-1fb0-4eb1-8cff-7b57f110990b,s-6b90e57e-3c81-44d8-8043-79988b6d8301This will put all of the organization_ids in a Set in Redis. You can pass a clear=true option to remove any organizations already in Redisbatch_process_organizations_for_check_task_synchronizationThis job takes two arguments:batch_size This defaults to 10, and controls how many organizations will be processed. Because the underlying code is prone to running out of memory, and can take a long time to process, it is best to work in smaller batches, and only queue up more after you have completed or killed the jobs in your batch.sync_tasks This defaults to false, and controls whether it will actually sync the tasks, or only report on what is out of sync. You usually want to run with true, but for spot checking, it can be helpful to use false. Keep in mind that if you use false , the organizations are still removed from Redis.Example:kubectl run-cmd -n content-flow-service --context production -s 2xlarge rake indexing:batch_process_organizations_for_check_task_synchronization batch_size=25 sync_tasks=trueThis job will spit out the organizations and job_ids that it enqueues. You should then follow the procedures above for each task (from Monitor The Task In NewRelic)Make sure you are keeping a CSV of any organization_ids you have to cancel, so you can do the manual task syncing later!Other ConsiderationsThese jobs can create a lot of data, which may be useful to you later. Consider capturing your console output in a txt document for later. You may also find value in querying NewRelic for event data after the fact, so be aware that NewRelic Log lines disappear after a week.Fixing the OOM issues with the sync check job would be amazing, as the manual process option is very painful.